{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df2f8d1-64b9-48ef-b453-ccf44718e7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1747674-78b0-493c-bbd5-e3685ae1339e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509e73aa-3613-4b9f-af72-ac317b2e93be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import treetaggerwrapper as ttpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ebf451-3c7e-485a-878e-3ebe98b3e6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861bc261-00d8-4e53-a435-f58c11bb5a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lerobert.scraping as lrs\n",
    "import lerobert.processing as lrp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2f086-98b5-4a39-8547-f28a1d6630d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fe472-338f-4682-ab37-1e9beb7ede40",
   "metadata": {},
   "source": [
    "If we look up French words \"pêche\" and \"péché\", they will be on the same page and have the same address \"https://dictionnaire.lerobert.com/definition/peche\". The last part of the address \"peche\" is going to be without any diacritics. To give the last part a separate term, we are going to call it a `word_path`. We are going to use the `word_path` as the `filename`, when saving the HTML of a page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a460d946-0f2c-4e55-b511-08a6da149bed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discovering Definition Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fcbff-e679-40bf-80c6-88d7c6c0f1be",
   "metadata": {},
   "source": [
    "`./lerobert/scraping.py` provides functions needed to discover valid `word_path`s when scraping the dictionary:\n",
    "1. The dictionary has \"Explorer le dictionnaire\" section, where it lists valid (and also not valid) links to the definitions. To find all the links in that section, you can use `get_explored_links()` function. \n",
    "2. You can also find definition pages via the API used by the built-in search. For this purpose, call `get_suggested_word_paths()` function with a search term as an argument.\n",
    "3. When you have saved some of the definition pages as HTML files, you can go over these files and extract all definition links via `find_word_paths_html_file()` function.\n",
    "4. The last option is to request a page and check its status code using `word_path` from a wordlist. Do not forget to remove diacritics and replace white spaces and `'` with `-` before that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc502c-e225-49d0-bea1-f501677434cf",
   "metadata": {},
   "source": [
    "All four approaches were taken to compile a list of valid valid definition pages `./assets/html/word_paths.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a4d82-9296-4bdf-aed2-9c6b6118af9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scraping the Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0a761-8bb8-470d-86b3-0a886ce6753a",
   "metadata": {},
   "source": [
    "Let's use `word_paths.txt` to download definition pages from this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf52742-84f3-429f-8549-f385a4379781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./assets/word_paths.txt', 'r', encoding='utf-8') as f:\n",
    "    word_paths = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798f23b-47f8-4754-9aed-69ce689d735a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5343a1b-8200-49ed-9406-eb7a7959c461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 305.48it/s]\n"
     ]
    }
   ],
   "source": [
    "results = lrp.execute_async(lrs.download_html, word_paths[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7860065-8f0c-4997-b8d5-3a9bea743ddb",
   "metadata": {},
   "source": [
    "`execute_async()` function is based on `concurrent.futures` module and will come in handy when downloading 51000+ pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8a61e-730a-4c25-895c-5ab539b07ed3",
   "metadata": {},
   "source": [
    "## Audio & Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fd7721-dd46-445f-b349-91297e7aaa91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "results = lrp.execute_async(lrs.download_media, lrp.list_html_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79971842-409b-43b0-8793-ec05eea252bb",
   "metadata": {},
   "source": [
    "## CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee717593-376c-403b-bf2f-b56ba6b20ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stylesheets = ['aside.css', 'commons.css']\n",
    "css_path = Path('./assets/css/')\n",
    "os.makedirs(css_path, exist_ok=True)\n",
    "for filename in stylesheets:\n",
    "    response = requests.get(f'https://dictionnaire.lerobert.com/statics/css/{filename}')\n",
    "    with open(css_path / Path(filename), 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462c742-5c70-452e-b108-6603ec9a7d32",
   "metadata": {},
   "source": [
    "## JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5af1f5-1058-4a29-bac4-fe07c892240c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'audioplayer.js'\n",
    "js_path = Path('./assets/js/')\n",
    "os.makedirs(js_path, exist_ok=True)\n",
    "response = requests.get(f'https://dictionnaire.lerobert.com/statics/js/{filename}')\n",
    "with open(js_path / Path(filename), 'w', encoding='utf-8') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40a4a7-eebb-4910-aec9-2ef4cbf04bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysing the Structure of HTML (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac2609-893b-432b-8f6e-9e1dd41233b0",
   "metadata": {},
   "source": [
    "Analysing the structure of HTML can be useful for figuring out what tags are found inside example tags (class=\"d_xpl\") and how often. We are going to take just the text part of example tags to get embeddings. To get the structure, we can use `find_definitions()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9eefeb-7bf9-40f3-96de-147f27894f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_file = lrp.list_html_files()[0]\n",
    "definition_tags = lrp.find_definitions(lrp.read_html_file(html_file))\n",
    "html_file, len(definition_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc05e4-3d0a-4f7d-94ca-4cc0c53d0052",
   "metadata": {},
   "source": [
    "Now, we can find all strings in a defintion tag and index them by their parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47312ef-e2ca-4c71-86d2-c932579085b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "results = lrp.execute_async(lrp.index_strings_by_parents, lrp.list_html_files()[:10], processes=True)\n",
    "string_parents = defaultdict(lambda: dict())\n",
    "for res_filename, res_parents in results:\n",
    "    for key, val in res_parents.items():\n",
    "        string_parents[key][res_filename] = val\n",
    "string_parents = dict(string_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a48cab-d2c1-444f-83ea-a369048458e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('h3', None), ('span', 'notBold'))\n",
      "(('h3', None),)\n",
      "(('h3', None), ('span', 'd_cat'))\n",
      "(('div', 'd_ptme'), ('span', 'd_dfn'))\n",
      "(('div', 'd_ptme'), ('span', 'd_dfn'), ('span', 'd_im'))\n"
     ]
    }
   ],
   "source": [
    "for key in list(string_parents.keys())[:5]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5082a41-bb37-49af-8c5d-4f2303bb8dcf",
   "metadata": {},
   "source": [
    "Each key is a tuple of tags also represented as tuples. After indexing, finding a page with and its content with a specific HTML structure becomes easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cbfb1f9-cb82-4c03-874e-34db7e7b656e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {0: [(1, 0, 0)], 1: [(1, 0, 0)], 2: [(1, 0, 0)], 3: [(1, 0, 0)]},\n",
       " 'a-b-c': {0: [(1, 0, 0)]},\n",
       " 'a-maxima': {0: [(1, 0, 0)]},\n",
       " 'a-contrario': {0: [(1, 0, 0)]},\n",
       " 'a-fortiori': {0: [(1, 0, 0)]},\n",
       " 'a-cappella': {0: [(1, 0, 0)]},\n",
       " 'a-coup': {0: [(1, 0, 0)]},\n",
       " 'a-cote': {0: [(1, 0, 0)]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_parents[(('h3', None), ('span', 'notBold'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e5ae0e-5bcb-438d-8b9f-3b26de1f431a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Définition de '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp.get_content(definition_tags[0], (1, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140e927-d3c1-4d5b-bdcd-5bef45b560e5",
   "metadata": {},
   "source": [
    "The dictionary contains plenty of examples for which it uses tags with `class=\"d_xpl\"`. Let's find all possible combinations with no more than one parent and one child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378803a9-8411-4e68-8a16-c0716e30a349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('div', 'd_dvl'), ('span', 'd_xpl')),\n",
       " (('div', 'd_dvl'), ('span', 'd_xpl'), ('span', 'd_lca')),\n",
       " (('div', 'd_dvl'), ('span', 'd_xpl'), ('span', 'd_mtb')),\n",
       " (('div', 'd_dvn'), ('span', 'd_xpl')),\n",
       " (('div', 'd_dvn'), ('span', 'd_xpl'), ('span', 'd_gls')),\n",
       " (('div', 'd_dvn'), ('span', 'd_xpl'), ('span', 'd_lca')),\n",
       " (('div', 'd_ptma'), ('span', 'd_xpl')),\n",
       " (('div', 'd_ptma'), ('span', 'd_xpl'), ('span', 'd_gls')),\n",
       " (('span', 'd_dvt'), ('span', 'd_xpl')),\n",
       " (('span', 'd_dvt'), ('span', 'd_xpl'), ('span', 'd_gls')),\n",
       " (('span', 'd_dvt'), ('span', 'd_xpl'), ('span', 'd_lca')),\n",
       " (('span', 'd_dvt'), ('span', 'd_xpl'), ('span', 'd_mtb')),\n",
       " (('span', 'd_dvt'), ('span', 'd_xpl'), ('span', 'd_rm'))}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_classes = set()\n",
    "for key in string_parents.keys():\n",
    "    for ind, tag in enumerate(key):  \n",
    "        if tag[1] == 'd_xpl':\n",
    "            tag_neighbors = key[ind-1:ind+2]\n",
    "            tag_classes.add(tag_neighbors)\n",
    "tag_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d6f46-1c7d-4e2f-9ede-c8db5224c248",
   "metadata": {},
   "source": [
    "The parent of an example tag (`class=\"d_xpl\"`) is a certain meaning in which the word is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef25984-7875-46f5-a1d5-f60da601bad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparing HTML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a93674-8787-4cd2-bd80-05b657995858",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wrapping words in example sentences in \"span\" tags with the class=\"word\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13794ce-db4d-4c26-a63d-ec69e58a70fe",
   "metadata": {},
   "source": [
    "Here, we are wrapping the word for which an example sentence is given into a tag with `class=\"word\"` which is used for pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ff110a-d0e7-41cc-ab62-e93ff955b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may also need to specify the directory of TreeTagger as TAGDIR='/home/user/treetagger'\n",
    "tagger = ttpw.TreeTagger(TAGLANG='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b71867-31b6-4aea-bc9a-795c27fa958e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "results = lrp.execute_async(lrp.process_html, lrp.list_html_files(), processes=False, tagger=tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06b8d0-2b6b-43ab-9e18-5a877a2c419c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mapping words in a definition header to that definition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98de2be-a2cb-4969-af31-07d051599709",
   "metadata": {},
   "source": [
    "We will use the words found in the headers of definitions as keys to get those definitions during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "542f0c10-7dbf-4db5-8351-d52fc18874d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.44it/s]\n"
     ]
    }
   ],
   "source": [
    "results = lrp.execute_async(lrp.map_words, lrp.list_html_files('./assets/html/processed/'), processes=False)\n",
    "full_word_map = defaultdict(lambda: defaultdict(lambda: []))\n",
    "for word_map in results:\n",
    "    for word, word_paths in word_map.items():\n",
    "        for word_path in word_paths:\n",
    "            full_word_map[word][word_path] = word_map[word][word_path]\n",
    "with open('./assets/word_map.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_word_map, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4890a-944c-401c-b01e-fb2b981a202c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computing Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e1336-a353-4043-85e5-92aa1432d0fd",
   "metadata": {},
   "source": [
    "Here, we are computing contextual embeddings for processed HTML files. These embeddings are used later to display how similar they are to the ones computed for a custom text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c27f04a1-917e-4810-a958-6f97f105f23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names = [\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "               \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955aa261-f435-430c-bf41-0b36e121e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    embedding_path = f'./assets/embeddings/{model_name}'\n",
    "    os.makedirs(embedding_path, exist_ok=True)\n",
    "    results = lrp.execute_async(lrp.compute_embeddings_html_file,\n",
    "                                lrp.list_html_files(html_path='./assets/html/processed'),\n",
    "                                processes=False,\n",
    "                                tokenizer=tokenizer,\n",
    "                                model=model,\n",
    "                                embedding_path=embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672e8db-62b7-4c63-a469-49730bc7a639",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Launching the App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3966e-2043-423a-97da-2dd8a0287e80",
   "metadata": {},
   "source": [
    "A simple interface of the app is provided in `./assets/index.html`. API calls made by the app are processed in `main.py`. To start the app: `uvicorn main:app --reload`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
